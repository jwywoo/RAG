{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Colab Imports"
      ],
      "metadata": {
        "id": "sBLGI9O7gs9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXcQXX-Cgsa1",
        "outputId": "1ebfb26a-595b-4b44-f822-99790bac0cb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations"
      ],
      "metadata": {
        "id": "Kot42h8ag6aG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2HGOQLyOn0lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09bf93c8-bd1e-499d-90d5-54eca2cfa597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m694.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.0/383.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-community faiss-cpu langchain-openai tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Json loading and directory path set"
      ],
      "metadata": {
        "id": "B4CbEggdg8cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "JSON_DIR_PATH = '/content/drive/MyDrive/RAG_JSON_EMBEDDINGS_INDEX'\n",
        "HA_RAG_DATA_PATH = os.path.join(JSON_DIR_PATH, \"JSON/HA_RAG_DATA\")\n",
        "if not os.path.exists(HA_RAG_DATA_PATH):\n",
        "    os.makedirs(HA_RAG_DATA_PATH)\n",
        "\n",
        "json_path = os.path.join(HA_RAG_DATA_PATH, \"combined_common.json\")\n",
        "\n",
        "with open(os.path.join(HA_RAG_DATA_PATH, json_path), \"r\") as f:\n",
        "        data = json.load(f)"
      ],
      "metadata": {
        "id": "zddk14ighYtI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index Path(Directory to save initialized index)\n",
        "DRIVE_PATH = '/content/drive/MyDrive/RAG_JSON_EMBEDDINGS_INDEX'\n",
        "INDEX_DIR_PATH = os.path.join(DRIVE_PATH, \"INDEX\")\n",
        "HA_INDEX_PATH = os.path.join(INDEX_DIR_PATH, \"HA_TEST_INDEX\")\n",
        "if not os.path.exists(INDEX_DIR_PATH):\n",
        "    os.makedirs(INDEX_DIR_PATH)\n",
        "\n",
        "if not os.path.exists(HA_INDEX_PATH):\n",
        "    os.makedirs(HA_INDEX_PATH)\n",
        "\n",
        "faiss_index_path = os.path.join(HA_INDEX_PATH, \"test_faiss_index\")"
      ],
      "metadata": {
        "id": "bGM6yF8zhgsj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Less Tokens: Meta Data"
      ],
      "metadata": {
        "id": "8o8CEzfuilfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_documents_meta = []\n",
        "import uuid\n",
        "from uuid import uuid4\n",
        "from langchain.schema import Document\n",
        "\n",
        "for row in data:\n",
        "  # Text\n",
        "  text = f\"{row['address']} [SEP] {row['location']} [SEP] \" \\\n",
        "  f\"{row['description']} [SEP] {row['rating']} [SEP] {row['share_link']} [SEP] \" \\\n",
        "  f\"{' '.join(row['reviews'])} [SEP] {row['info']}\"\n",
        "  # Metadata\n",
        "  metadata = {\n",
        "      \"ad_gu\": row['ad_gu'],\n",
        "      \"ad_dong\": row['ad_dong'],\n",
        "  }\n",
        "  clean_text = text.replace(\"\\n\", \" \")\n",
        "  test_documents_meta.append(Document(\n",
        "      page_content=clean_text,\n",
        "      metadata=metadata\n",
        "  ))\n",
        "\n",
        "# Only for Faiss -> comment it out for Pinecone\n",
        "uuids = [str(uuid4()) for _ in range(len(test_documents_meta))]"
      ],
      "metadata": {
        "id": "PkQENiPKl7jS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_docuemtns_no_meta = []\n",
        "import uuid\n",
        "from uuid import uuid4\n",
        "from langchain.schema import Document\n",
        "\n",
        "for row in data:\n",
        "  text = f\"{row['ad_gu']} [SEP] {row['ad_dong']} [SEP] {row['address']} [SEP] {row['location']} [SEP] \" \\\n",
        "               f\"{row['description']} [SEP] {row['rating']} [SEP] {row['share_link']} [SEP] \" \\\n",
        "               f\"{' '.join(row['reviews'])} [SEP] {row['info']}\"\n",
        "  clean_text = text.replace(\"\\n\", \" \")\n",
        "  test_docuemtns_no_meta.append(Document(page_content=clean_text))\n",
        "\n",
        "# Only for Faiss -> comment it out for Pinecone\n",
        "uuids = [str(uuid4()) for _ in range(len(test_docuemtns_no_meta))]"
      ],
      "metadata": {
        "id": "qhK55ezFxMTj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.encoding_for_model(\"text-embedding-3-large\")\n",
        "\n",
        "no_meta_avg_token_num = 0\n",
        "meta_avg_token_num = 0\n",
        "\n",
        "for i in range(100):\n",
        "  no_meta_avg_token_num += len(tokenizer.encode(test_docuemtns_no_meta[i].page_content))\n",
        "  meta_avg_token_num += len(tokenizer.encode(test_documents_meta[i].page_content))\n",
        "\n",
        "no_meta_avg_token_num /= 100\n",
        "meta_avg_token_num /= 100\n",
        "print(f\"No Meta Avg Token Num: {no_meta_avg_token_num}\")\n",
        "print(f\"Meta Avg Token Num: {meta_avg_token_num}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3jWHV-UnOR4",
        "outputId": "edde12a1-b3df-4b22-d550-41d451e1eda7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Meta Avg Token Num: 1057.13\n",
            "Meta Avg Token Num: 1042.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Store Init"
      ],
      "metadata": {
        "id": "jB_XNbEJx-BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FAISS init\n",
        "import faiss\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Embedding Model Selection\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openAI')\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "\n",
        "# Index Dimension\n",
        "index_cpu = faiss.IndexFlatL2(len(embeddings.embed_query(test_documents_meta[0].page_content)))\n",
        "\n",
        "vector_store = FAISS(\n",
        "    embedding_function=embeddings,\n",
        "    index=index_cpu,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={},\n",
        ")"
      ],
      "metadata": {
        "id": "-reDgsLhmcF_"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}